import warnings

import lightning.pytorch as pl
import numpy as np
import torch
import torchvision
from torch import nn
from torch.optim.lr_scheduler import LambdaLR
import math
import torch.nn.functional as F
from torchvision.models import Swin_V2_S_Weights


def warmup_cosine_annealing_lambda(current_epoch, warmup_epochs, total_epochs, warmup_lr_ratio, min_lr_ratio):
    if current_epoch < warmup_epochs:
        # Linear warmup
        alpha = current_epoch / warmup_epochs
        return (1 - alpha) + alpha * warmup_lr_ratio
    else:
        # Cosine annealing
        t = (current_epoch - warmup_epochs) / (total_epochs - warmup_epochs)
        cos_anneal = 0.5 * (1 + math.cos(math.pi * t))
        return min_lr_ratio + (warmup_lr_ratio - min_lr_ratio) * cos_anneal


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    with torch.no_grad():
        return _trunc_normal_(tensor, mean, std, a, b)


def _trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    # Values are generated by using a truncated uniform distribution and
    # then using the inverse CDF for the normal distribution.
    # Get upper and lower cdf values
    l = norm_cdf((a - mean) / std)
    u = norm_cdf((b - mean) / std)

    # Uniformly fill tensor with values from [l, u], then translate to
    # [2l-1, 2u-1].
    tensor.uniform_(2 * l - 1, 2 * u - 1)

    # Use inverse cdf transform for normal distribution to get truncated
    # standard normal
    tensor.erfinv_()

    # Transform to proper mean, std
    tensor.mul_(std * math.sqrt(2.))
    tensor.add_(mean)

    # Clamp to ensure it's in the proper range
    tensor.clamp_(min=a, max=b)
    return tensor


def norm_targets(targets, patch_size):
    assert patch_size % 2 == 1

    targets_ = targets
    targets_count = torch.ones_like(targets)

    targets_square = targets ** 2.

    targets_mean = F.avg_pool2d(targets, kernel_size=patch_size, stride=1, padding=patch_size // 2,
                                count_include_pad=False)
    targets_square_mean = F.avg_pool2d(targets_square, kernel_size=patch_size, stride=1, padding=patch_size // 2,
                                       count_include_pad=False)
    targets_count = F.avg_pool2d(targets_count, kernel_size=patch_size, stride=1, padding=patch_size // 2,
                                 count_include_pad=True) * (patch_size ** 2)

    targets_var = (targets_square_mean - targets_mean ** 2.) * (targets_count / (targets_count - 1))
    targets_var = torch.clamp(targets_var, min=0.)

    targets_ = (targets_ - targets_mean) / (targets_var + 1.e-6) ** 0.5

    return targets_


class SimMimEncoder(nn.Module):
    def __init__(self, encoder, patch_size=(4, 4)):
        super(SimMimEncoder, self).__init__()
        self.patch_size = patch_size
        # embed size is 128 in swin_v2_b
        self.encoder = encoder
        self.encoder_stride = 32

        self.mask_token = nn.Parameter(torch.zeros(1, 1, self.encoder.features[0][0].out_channels))
        trunc_normal_(self.mask_token, mean=0., std=.02)

    def forward(self, x, mask):
        # patch embedding
        z = self.encoder.features[0](x)
        # masking
        assert mask is not None
        B, H, W, _ = z.shape
        mask_tokens = self.mask_token.expand(B, H, W, -1)
        w = mask.flatten(2).unsqueeze(-1).type_as(mask_tokens)
        z = z * (1. - w) + mask_tokens * w
        z = self.encoder.features[1:](z)
        z = self.encoder.norm(z)
        z = self.encoder.permute(z).contiguous()
        mask = mask.repeat_interleave(self.patch_size[0], 1).repeat_interleave(self.patch_size[1], 2).unsqueeze(
            1).contiguous()
        return z, mask


class SimMimDecoder(nn.Module):
    def __init__(self, encoder_stride, in_channels, out_channels):
        super(SimMimDecoder, self).__init__()
        self.decoder = nn.Sequential(
            nn.Conv2d(
                in_channels=in_channels,
                out_channels=out_channels, kernel_size=1),
            nn.PixelShuffle(encoder_stride),
        )

    def forward(self, x):
        return self.decoder(x)
